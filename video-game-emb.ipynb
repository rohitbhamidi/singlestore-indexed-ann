{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Wikipedia:Good_articles/Video_games')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "urls = [link.get('href') for link in links if link.get('href') is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_patterns = [\n",
    "    '#',  # Anchor links\n",
    "    '/wiki/Main_Page',\n",
    "    '/wiki/Wikipedia:',\n",
    "    '/wiki/Portal:',\n",
    "    '/wiki/Special:',\n",
    "    '/wiki/Help:',\n",
    "    '//en.wikipedia.org/wiki/Wikipedia:',\n",
    "    'https://donate.wikimedia.org/wiki/Special:',\n",
    "    '/w/index.php?title=Special:',\n",
    "    '/wiki/Special:My',\n",
    "    'https://www.wikidata.org/wiki/Special:',\n",
    "    '/w/index.php?title=',\n",
    "    '/wiki/File:',\n",
    "    '/wiki/Category:',\n",
    "    '/wiki/Template:',\n",
    "    '/wiki/Wikipedia_talk:',\n",
    "    '/wiki/User:',\n",
    "]\n",
    "\n",
    "filtered_urls = ['https://en.wikipedia.org' + url for url in urls if not any(pattern in url for pattern in excluded_patterns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'admin'\n",
    "passkey = getpass.getpass('Enter your SingleStore admin password: ')\n",
    "connection_string = 'svc-4d9215ce-fc86-42cb-9bf7-c5e1383bb647-dml.aws-oregon-4.svc.singlestore.com'\n",
    "port = '3306'\n",
    "database = 'wikipedia_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SingleStore\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(f'mysql+pymysql://{username}:{passkey}@{connection_string}:{port}/{database}')\n",
    "conn = engine.connect()\n",
    "print('Connected to SingleStore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "API_KEY = getpass.getpass('OpenAI API Key: ')\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table():\n",
    "    '''Creates the table in SingleStore'''\n",
    "    conn.execute(sa.text('''DROP TABLE IF EXISTS wiki_scrape;'''))\n",
    "    conn.execute(sa.text('''\n",
    "    CREATE TABLE wiki_scrape(\n",
    "        id BIGINT AUTO_INCREMENT PRIMARY KEY,\n",
    "        url VARCHAR(255),\n",
    "        paragraph TEXT,\n",
    "        embedding VECTOR(1536, F32) NOT NULL,\n",
    "        FULLTEXT (paragraph),\n",
    "        VECTOR INDEX (embedding) INDEX_OPTIONS '{\"index_type\":\"IVF_PQ\"}'\n",
    "    );\n",
    "    '''))\n",
    "    print('Table created')\n",
    "\n",
    "def clear_table():\n",
    "    '''Clears the table of all data'''\n",
    "    conn.execute(sa.text('TRUNCATE TABLE wiki_scrape;'))\n",
    "    print('Table cleared of all data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table cleared of all data\n"
     ]
    }
   ],
   "source": [
    "clear_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''cleans the text of a wiki page'''\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\<.*?\\>', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\t', '', text)\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def get_text(url):\n",
    "    '''Gets the text from a wiki page and returns it as a string.'''\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        page.raise_for_status()  # Raises an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        cleaned_paragraphs = [clean_text(p.text) for p in paragraphs if p.text.strip()]\n",
    "        return cleaned_paragraphs\n",
    "    except requests.RequestException as e:\n",
    "        # print(f\"Error fetching URL {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_embedding(text, model=EMBEDDING_MODEL):\n",
    "    '''Generates the OpenAI embedding from an input `text`.'''\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            response = client.embeddings.create(input=[text], model=model)\n",
    "            embedding = response.data[0].embedding\n",
    "            # return np.array(embedding).tobytes()\n",
    "            return json.dumps(embedding)\n",
    "        else:\n",
    "            # print(f\"Invalid input: {text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def text_embedding_df(url):\n",
    "    '''Creates a dataframe of the text from a wiki page and the OpenAI embeddings of that text'''\n",
    "    text = get_text(url)\n",
    "    embeddings = [get_embedding(t) for t in text]\n",
    "    df = pd.DataFrame({'paragraph': text, 'embedding': embeddings})\n",
    "    return df\n",
    "\n",
    "def scrape_wiki(url_list, table_name, engine):\n",
    "    '''Pushes a dataframe to a SingleStore table'''\n",
    "    for url in tqdm(url_list):\n",
    "        dataframe = text_embedding_df(url)\n",
    "        dataframe['url'] = url \n",
    "        dataframe = dataframe[['url', 'paragraph', 'embedding']]\n",
    "        dataframe = dataframe[dataframe['embedding'].notna()]\n",
    "        dataframe.to_sql(table_name, con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wiki_page(query, limit=5):\n",
    "    '''Returns a df of the top k matches to the query ordered by similarity.'''\n",
    "    query_embedding_vec = get_embedding(query)\n",
    "    # cast query embedding to vector data type :> vector(1536) - returning json dumps in embedding\n",
    "    statement = sa.text(\n",
    "        f'''SELECT paragraph, v <*> :query_embedding :> vector(1536) AS similarity\n",
    "        FROM vecs\n",
    "        ORDER BY similarity USE INDEX (ivfpq) DESC\n",
    "        LIMIT :limit;'''\n",
    "    )\n",
    "    print(\"Searching for matches...\")\n",
    "    start_time = time.time()\n",
    "    results = conn.execute(statement, {\"query_embedding\": query_embedding_vec, \"limit\": limit})\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Search complete in {execution_time} seconds.\")\n",
    "    results_as_dict = results.fetchall()\n",
    "    return results_as_dict\n",
    "\n",
    "def ask_wiki_page(query, limit=5, temp=0.0):\n",
    "    '''Uses a RAG to answer a question from the wiki page'''\n",
    "    results = search_wiki_page(query, limit)\n",
    "    print(\"Asking Chatbot...\")\n",
    "    prompt = f'''Excerpt from the conversation history: \n",
    "        {results}\n",
    "        Question: {query}\n",
    "        \n",
    "        Based on the conversation history, try to provide the most accurate answer to the question. \n",
    "        Consider the details mentioned in the conversation history to formulate a response that is as \n",
    "        helpful and precise as possible. please provide links to WIKIPEDIA ARTICLES TO LOOK AT FOR MORE INFORMATION.\n",
    "\n",
    "        Most importantly, IF THE INFORMATION IS NOT PRESENT IN THE CONVERSATION HISTORY, PLEASE DO NOT MAKE UP AN ANSWER.'''\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who is answering questions about an article.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temp\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for matches...\n",
      "Search complete in 0.19211912155151367 seconds.\n",
      "Asking Chatbot...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The Mario video game franchise is known for its platform games featuring the iconic character Mario. It was developed and published by Nintendo, starting with the arcade game Mario Bros. in 1983. The franchise was designed by Shigeru Miyamoto and Gunpei Yokoi. Mario Bros. was followed by Super Mario RPG, which was critically acclaimed for its humor and 3D-rendered graphics. This game inspired Nintendo's other role-playing series, Paper Mario and Mario & Luigi. Another notable game in the franchise is Superstar Saga, developed by AlphaDream and directed by Yoshihiko Maekawa. It features the voice of Charles Martinet, who is the official voice of Mario in Nintendo's Mario franchise. The franchise also includes games like Super Mario Land, Hotel Mario, and Super Mario Kart. For more detailed information, you can refer to the Wikipedia articles on the Mario franchise (https://en.wikipedia.org/wiki/Mario) and its individual games.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_wiki_page(\"Tell me about the Mario video game franchise and its history. What is it known for?\", limit=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
